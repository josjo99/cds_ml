{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f581d046",
   "metadata": {},
   "source": [
    "# CDS ML Assignment 6\n",
    "##### Group 37 - Rahul Deivasigamani (S1157698) - Joshua John Gigi (S1140063) - Anestis Pantazis (S1169388)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a829099",
   "metadata": {},
   "source": [
    "## 6.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7551e",
   "metadata": {},
   "source": [
    "## 6.2. \n",
    "\n",
    "The phenomenon of explaining away is exemplified by $p(x_i=1|y,x_1=1) < p(x_i=1|y)$: the certainty that disease 1 is present $(x_1 = 1)$ partly explains the observed fever $y$ and makes the other causes $x_i$ less likely. We study this in detail for a Gaussian directed model with two causes and one effect with  $x_{1,2}$ two standard Normal variables $p(x_i)= N(x_i|0,1),i=1,2$ and  y depending on  x1,2 as  p(y|x1,x2)=N(y|γ(x1+x2),σ2) .We will compute the correlation between $x_1$  and  $x_2$ in the conditional distribution $p(x_1,x_2|y)$. Proceed in the following way: \n",
    "\n",
    "* Compute the joint distribution  $p(x_1,x_2,y)=p(x_1)p(x_2)p(y|x_1,x_2)$ [Hint: try to do it without completing the square.]\n",
    "* Compute the conditional distribution $p(x1,x2|y)$;\n",
    "* With $\\Sigma$ the covariance matrix between $x_1$,$x_2$ in the posterior distribution $p(x_1,x_2|y)$, compute the correlation coefficient $\\rho = \\frac{\\Sigma_{12}}{\\sqrt{\\Sigma_{11}\\Sigma_{22}}}$ and show that while a priori $x_1$,$x_2$ are independent, when $y$ is observed they become anti-correlated.\n",
    "\n",
    "A similar phenomenon happens in the tabular binary case as well, in such a way that $x_1$ and $x_2$ become anti-correlated when $y$ is observed: observing $x_1=1$ increases the probability that $x_2=0$, making the cause $x_2$ less likely, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa53a61",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c9145",
   "metadata": {},
   "source": [
    "#### Joint Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a9229",
   "metadata": {},
   "source": [
    "$p(x_1​)=\\mathcal{N}(x_1​∣0,1)$\n",
    "\n",
    "$p(x_2​)=\\mathcal{N}(x_2​∣0,1)$\n",
    "\n",
    "$p(y∣x_1​,x_2​)=\\mathcal{N}(y∣\\gamma(x_1​+x_2​),\\sigma^2)$\n",
    "\n",
    "$p(x_1​,x_2,y​)=p(x_1)p(x_2)p(y|x_1,x_2) = \\frac{1}{(2\\pi)^{3/2}\\sigma}exp\\left(-\\frac{1}{2}x_1^2 -\\frac{1}{2}x_2^2 -\\frac{1}{2\\sigma^2}(y-\\gamma(x_1+x_2))^2\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b639bfa",
   "metadata": {},
   "source": [
    "#### Conditional Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a639b0",
   "metadata": {},
   "source": [
    "$x_1 \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "$x_2 \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "$y|x_1,x_2 \\sim \\mathcal{N}(\\gamma(x_1+x_2),\\sigma^2)$\n",
    "\n",
    "$\\begin{bmatrix} x_1\\\\ x_2\\\\ y \\end{bmatrix} \\sim \\mathcal{N}(0,\\Sigma)$\n",
    "\n",
    "$\\sigma(x_1)=1, \\sigma(x_2)=1$ \n",
    "\n",
    "$\\sigma(y) = \\sigma(\\gamma(x_1+x_2)+\\eta) = \\gamma^2(\\sigma(x_1)+ \\sigma(x_2)+ 2Cov(x_1,x_2))+\\sigma^2 = 2\\gamma^2+\\sigma^2 $\n",
    "\n",
    "$\\Sigma = \\begin{bmatrix} 1 & 0 & \\gamma\\\\ 0 & 1 & \\gamma \\\\ \\gamma & \\gamma & 2\\gamma^2+\\sigma^2 \\end{bmatrix}$\n",
    "\n",
    "For multivariate gausians joint distribution, conditional distribution of subset of variables is computed using partitioned covariance matrix.\n",
    "\n",
    "So, $\\Sigma_{11} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$,$\\Sigma_{12} = \\begin{bmatrix} \\gamma \\\\ \\gamma \\end{bmatrix}$,$\\Sigma_{21} = \\Sigma_{12}^T = \\begin{bmatrix} \\gamma & \\gamma \\end{bmatrix}$,$\\Sigma_{22} = 2\\gamma^2+\\sigma^2$\n",
    "\n",
    "Conditional Covariance of $x_1, x_2|y$,\n",
    "\n",
    "$\\Sigma_{(x_1,x_2)|y} = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$\n",
    "\n",
    "$\\Sigma_{x_1,x_2|y} = \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix} - \\frac{1}{2\\gamma^2+\\sigma^2} \\begin{bmatrix} \\gamma \\\\ \\gamma\\end{bmatrix} \\begin{bmatrix} \\gamma & \\gamma\\end{bmatrix}$\n",
    "\n",
    "$\\Sigma_{x_1,x_2|y}= \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix} - \\frac{1}{2\\gamma^2+\\sigma^2} \\begin{bmatrix} \\gamma^2 & \\gamma^2 \\\\ \\gamma^2 & \\gamma^2\\end{bmatrix}$\n",
    "\n",
    "$\\Sigma_{x_1,x_2|y} = \\begin{bmatrix} 1 - \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2} & - \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2} \\\\ - \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2} & 1 - \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8b5b5",
   "metadata": {},
   "source": [
    "#### Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ed595",
   "metadata": {},
   "source": [
    "$\\rho = \\frac{\\Sigma_{12}}{\\sqrt{\\Sigma_{11}\\Sigma_{22}}}$\n",
    "\n",
    "$\\rho = \\frac{- \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2}}{1 - \\frac{\\gamma^2}{2\\gamma^2+\\sigma^2}}$\n",
    "\n",
    "$\\rho = -\\frac{\\gamma^2}{\\gamma^2+\\sigma^2}$\n",
    "\n",
    "Since $\\gamma^2 >0 $,$\\sigma^2 > 0$, correlation coefficient $\\rho$ is negative. Negative correlation indicates that the variables $x_1$, $x_2$ are anti-correlated. This occurs due to the influence of $y$ "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
