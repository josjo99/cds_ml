{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a128020-0ecb-4ab0-8b6a-bb91eaa333d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial, comb\n",
    "from scipy.stats import gamma, beta\n",
    "\n",
    "from scipy.special import gamma as gamma_func\n",
    "from scipy.special import beta as beta_func\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8db42-4936-42df-9e0d-da25577c10eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Lecture 2: Model comparison\n",
    "\n",
    "* **2.1 Bayesian estimation**\n",
    "    * Bayesian inference over discrete variable\n",
    "    * Bayesian inference over continuous variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082ff2b-54ab-41c5-93f5-b86cccabe1d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Bayesian inference over discrete variable\n",
    "\n",
    "### Exercise (Mackay Ex 3.1)\n",
    "\n",
    "A die is selected at random from two 20-faced dice on which the symbols 1-10 are written with nonuniform frequency as follows:\n",
    "\n",
    "| Symbol | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Number of faces of die **A** | 6 | 4 | 3 | 2 | 1 | 1 | 1 | 1 | 1 | 0 |\n",
    "| Number of faces of die **B** | 3 | 3 | 2 | 2 | 2 | 2 | 2 | 2 | 1 | 1 |\n",
    "\n",
    "The randomly chosen die is rolled  7 times, with the following outcomes:\n",
    "\n",
    "<center>5, 3, 9, 3, 8, 4, 7</center>\n",
    "\n",
    "What is the probability that the die was die **A**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124526e8-1061-40d7-802b-b7e918876223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Solution\n",
    "\n",
    "Denote $x=A,B$ the two dice.\n",
    "\n",
    "Denote $y=1,\\ldots,10$ the possible outcomes of a single throw of a die.\n",
    "\n",
    "Denote $D=\\{5,3,9,3,8,4,7\\}=\\{y_1,\\ldots,y_7\\}$ the observed data.\n",
    "\n",
    "We wish to compute the probability of $x=A,B$ given the observed data $D$, i.e. $p(x|D)$ from Bayes' rule:\n",
    "$$p(x|D)=\\frac{p(D|x)p(x)}{p(D)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2961d0b-f5dd-4d0f-bbba-a9d6da1c36d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "$p(D|x)$ is the probability to observe the data under the two different models (dice):\n",
    "$$p(D|x=A)=\\prod_{i=1}^7 p(y_i|x=A)=\\frac{1\\cdot3\\cdot1\\cdot3\\cdot1\\cdot2\\cdot1}{20^7}=\\frac{18}{20^7}$$\n",
    "$$p(D|x=B)=\\prod_{i=1}^7 p(y_i|x=B)=\\frac{2\\cdot2\\cdot1\\cdot2\\cdot2\\cdot2\\cdot2}{20^7}=\\frac{64}{20^7}$$\n",
    "\n",
    "$p(x)=1/2$ is the prior probability to choose a die.\n",
    "\n",
    "The ratio of the two posterior probabilities is easily calculated:\n",
    "$$\\frac{p(D|x=A)}{p(D|x=B)}=\\frac{p(x=A|D)}{p(x=B|D)}=\\frac{18}{64}=\\frac{9}{32}$$\n",
    "\n",
    "and since $p\\left(D\\right)=\\frac{18}{20^{7}}\\frac{1}{2}+\\frac{64}{20^{7}}\\frac{1}{2}$ we get:\n",
    "$$p(x=A|D)=\\frac{8}{8+64}=\\frac{9}{41}\\qquad p(x=B|D)=\\frac{32}{8+64}=\\frac{32}{41}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48e816-8d36-4de4-87e1-05c33d3da45d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Bayesian inference over continuous variable\n",
    "\n",
    "### Example of decaying particle\n",
    "\n",
    "<center><img src=\"figs/evidence_decay_constant.png\" width=500></center>\n",
    "\n",
    "Given $\\lambda$, the probability to observe $x_i$ is $p_0(x_i|\\lambda)=\\frac{1}{\\lambda}e^{-x_i/\\lambda}$.\n",
    "\n",
    "When we can observe only $ 1 \\le x \\le 20$, we need to renormalize the exponential distribution in a restricted support:\n",
    "$$p(x|\\lambda)=\\frac{1}{Z(\\lambda)}p_0(x|\\lambda) \\qquad 1\\le x \\le 20$$\n",
    "$$= 0 \\qquad \\text{else}$$$$Z(\\lambda)=\\int_1^{20} dx p_0(x|\\lambda)=e^{-1/\\lambda}-e^{-20/\\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbde25b-ed16-4521-b43b-fe1c1f78de08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Since the particles decay independently, the probability of the data set $D=\\{x_1,\\ldots,x_N\\}$ is the product of the probability of the data points\n",
    "$$p(D|\\lambda)=\\prod_{i=1}^N p(x_i|\\lambda)$$\n",
    "\n",
    "Using Bayes' rule:\n",
    "$$p(\\lambda|D)=\\frac{p(D|\\lambda)p(\\lambda)}{p(D)}=\\frac{1}{p(D)}\\frac{1}{\\left(\\lambda Z(\\lambda)\\right)^N} \\exp\\left(-\\sum_{i=1}^N x_i/\\lambda\\right)p(\\lambda)$$\n",
    "$$p(D)=\\int_0^\\infty \\frac{1}{\\left(\\lambda Z(\\lambda)\\right)^N} \\exp\\left(-\\sum_{i=1}^N x_i/\\lambda\\right)p(\\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22246d1f-429c-4e3e-8f87-b7f5b85053b1",
   "metadata": {},
   "source": [
    "Let's visualize the likelihood for a single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd4b6a-b049-4663-b0fc-07dee1e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = lambda lam : np.exp(-1./lam) - np.exp(-20./lam)\n",
    "def p_x_lam(x, lam):\n",
    "    return (x > 1.) * np.exp(-x/lam)/lam/Z(lam)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# visualize prob of x given λ\n",
    "plt.subplot(121)\n",
    "lams = [2.,5.,10.]\n",
    "x_plot = np.linspace(0., 20., 100)\n",
    "for lam in lams:\n",
    "    plt.plot(x_plot, p_x_lam(x_plot, lam), label=f\"λ = {lam}\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('P(x|λ')\n",
    "plt.legend();\n",
    "\n",
    "# visualize likelihood (note that the function over λ is not normalized)\n",
    "plt.subplot(122)\n",
    "xs = [3., 5., 12]\n",
    "lam_plot = np.logspace(-1, 2, 100)\n",
    "for x in xs:\n",
    "    plt.plot(lam_plot, p_x_lam(x, lam_plot), label=f\"x = {x}\")\n",
    "plt.vlines(x=lams, ymin=0, ymax=0.2, ls='--', color='gray')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('λ')\n",
    "plt.ylabel('P(x|λ')\n",
    "plt.legend();\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dea0d-dd22-450c-abf6-7973fa3afca2",
   "metadata": {},
   "source": [
    "and the likelihood for the data set $D=\\{1.5, 2, 3, 4, 5, 12\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1524c-9eb4-4604-b3b4-87409c35b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1.5, 2., 3., 4., 5., 12.])\n",
    "\n",
    "p_D_lam = [np.prod(p_x_lam(data, lam)) for lam in lam_plot]\n",
    "\n",
    "plt.plot(lam_plot, p_D_lam)\n",
    "plt.xscale('log');\n",
    "plt.xlabel('λ')\n",
    "plt.ylabel('P(D|λ)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855eec00-3db6-452f-b347-5ff346ee6b51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction to Model comparison\n",
    "\n",
    "### A new look at the bent coin\n",
    "\n",
    "A bent coin is tossed $N$ times with $N_H$ times outcome 'head' and $N-N_H$ times outcome 'tail'.\n",
    "We consider two hypotheses:\n",
    "* $H_0$: the coin is fair with probability 'head' is $1/2$\n",
    "* $H_1$: the coin is not fair. $\\lambda$ is the probability of outcome 'head'. Our prior assumption about $\\lambda$ is $p(\\lambda)=1$.\n",
    "\n",
    "Assuming equal prior probabilities on the hypotheses, $p(H_0)=p(H_1)=1/2$, what is the probability of each of the hypotheses after seeing the data $D$?\n",
    "\n",
    "Bayes' rule and equal prior probabilities lead to ratio of posterior being ratio of likelihood of hypotheses (**evidence**):\n",
    "$$p(H_i|D)=\\frac{p(D|H_i) p(H_i)}{p(D)}\\qquad \\frac{p(H_1|D)}{p(H_0|D)}=\\frac{p(D|H_1)}{p(D|H_0)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a826f2f-a683-4a8a-b4ef-bbe853739486",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "$H_0$:\n",
    "$$p(D|H_0)= \\left(\\frac{1}{2}\\right)^{N_H}\\left(\\frac{1}{2}\\right)^{N-N_H}= \\left(\\frac{1}{2}\\right)^{N}$$$H_1$:$$p(D|\\lambda,H_1)=\\lambda^{N_H}(1-\\lambda)^{N-N_H}$$$$p(\\lambda|H_1)=1\\qquad \\left(\\text{Note:} \\int_0^1 d\\lambda p(\\lambda|H_1)=1\\right)$$$$p(D|H_1)=\\int_0^1 d\\lambda p(\\lambda|H_1)p(D|\\lambda,H_1)=\\int_0^1 d\\lambda \\lambda^{N_H}(1-\\lambda)^{N-N_H}=\\frac{N_H! (N-N_H)!}{(N+1)!}$$\n",
    "(recall Beta function from Lec 1).\n",
    "\n",
    "Thus\n",
    "$$\\frac{p(H_1|D)}{p(H_0|D)}=2^N \\frac{N_H! (N-N_H)!}{(N+1)!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb94f1-46b4-40fa-89b7-4516471a4a1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Consider a different hypothesis $H_0$:\n",
    "\n",
    "The coin is unfair with probability 'head' $p_0=1/6$. Then:\n",
    "$$\\frac{p(H_1|D)}{p(H_0|D)}=\\frac{\\frac{N_H! (N-N_H)!}{(N+1)!}}{p_0^{N_H}(1-p_0)^{N-N_H}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65100d-290d-4a6c-abd4-afab8051762f",
   "metadata": {},
   "source": [
    "Let's look at the outcome of model comparison between model $H_0$ and $H_1$ (Mackay Table 3.5, note that we changed $N$→$F$, $N_H$→$F_a$ ,$N-N_H$→$F_b$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624350e-4066-4f13-80e5-6696fc134a41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def odd_ratio(Fa, Fb, p0):\n",
    "    ratio = factorial(Fa) * factorial(Fb) / factorial(Fa + Fb + 1) / (p0**Fa * (1 - p0)**Fb)\n",
    "    return ratio\n",
    "\n",
    "p0 = 1/6\n",
    "\n",
    "print(\"total number of tosses F = 6:\")\n",
    "for FaFb in [(5, 1),\n",
    "             (3, 3),\n",
    "             (2, 4),\n",
    "             (1, 5),\n",
    "             (0, 6)]:\n",
    "    \n",
    "    print(\"(Fa, Fb) :\\t\", FaFb, \"\\tratio:\\t\", odd_ratio(*FaFb, p0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcbc66-c25a-4aff-a070-f9dba043b0fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p0 = 1/6\n",
    "\n",
    "print(\"total number of tosses F = 20\")\n",
    "for FaFb in [(10, 10),\n",
    "             (3, 17),\n",
    "             (0, 20)]:\n",
    "    \n",
    "    print(\"(Fa, Fb) :\\t\", FaFb, \"\\tratio:\\t\", odd_ratio(*FaFb, p0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd6458-0b22-4eac-a888-39e31362fe41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The simple model $H_0$ 'likes' $(1,5)$ or $(3,17)$. The complex model $H_1$ 'likes' all outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd05c80-a2f8-466c-b20c-50e0215b21d2",
   "metadata": {},
   "source": [
    "### Evidence accumulation (Mackay Fig. 3.6)\n",
    "\n",
    "Let's have a look at the typical behaviour of the evidence in favour of $H_1$ as bent coin tosses accumulate.\n",
    "\n",
    "Try out different possibilities for `pa`:\n",
    "\n",
    "`pa = 1/6`\n",
    "\n",
    "`pa = 0.25`\n",
    "\n",
    "`pa = 0.5`\n",
    "\n",
    "and look at how evidence evolves as the number of draws grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9f1b8-d67c-498b-aea5-0a6d716c427d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pa = 0.5\n",
    "\n",
    "num_draws = 200\n",
    "\n",
    "draws = (np.random.rand(num_draws) < pa) * 1\n",
    "\n",
    "Fas = np.cumsum(draws)\n",
    "Fbs = np.arange(1, num_draws + 1) - Fas\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "odds = odd_ratio(Fas, Fbs, p0)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(Fas);\n",
    "plt.xlabel('draws')\n",
    "plt.ylabel('# of heads');\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hlines(y=0, xmin=0, xmax=num_draws, ls=':', color='gray')\n",
    "plt.plot(np.log(odds), '.-');\n",
    "plt.xlabel('draws')\n",
    "plt.ylabel('log [P(s|F, $H_1$)/P(s|F, $H_0$)]');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417423d-0ae8-44b4-8de6-01b710e161db",
   "metadata": {},
   "source": [
    "# <center>Assignments</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddca132-88e1-4c6f-a0dc-236a61aa7b19",
   "metadata": {},
   "source": [
    "#### Ex 2.1 (MacKay Ex 3.12)\n",
    "\n",
    "A bag contains one counter, known to be either white or black. A white\n",
    "counter is put in, the bag is shaken, and a counter is drawn out,\n",
    "which proves to be white. What is now the chance of drawing a white\n",
    "counter? [Notice that the state of the bag, after the operations,\n",
    "is exactly identical to its state before.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f47ef0",
   "metadata": {},
   "source": [
    "$H_B:$ Counter is Black\n",
    "\n",
    "$H_W:$ Counter is White\n",
    "\n",
    "$E:$ First Counter drawn is white\n",
    "\n",
    "$P(E|H_B) = \\frac{1}{2}$\n",
    "\n",
    "$P(E|H_W) = 1$\n",
    "\n",
    "$P(H_W|E) = \\frac{P(E|H_W)\\cdot P(H_W)}{P(E|H_W) \\cdot P(H_W) + P(E|H_B) \\cdot P(H_B)}  $\n",
    "\n",
    "$P(H_W|E) = \\frac{1 \\cdot \\frac{1}{2}}{1 \\cdot \\frac{1}{2} + \\frac{1}{2} \\cdot \\frac{1}{2}} $\n",
    "\n",
    "$P(H_W|E) = \\frac{2}{3} $\n",
    "\n",
    "$P(H_B|E) = \\frac{1}{3} $\n",
    "\n",
    "$P(W) = $P(H_W|E) \\cdot 1 + $P(H_B|E) \\cdot 0$\n",
    "\n",
    "$P(W) = \\frac{2}{3}$\n",
    "\n",
    "i.e P(next counter being white) = 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026fac8-eaad-49bd-89b1-5a1f4b3431e1",
   "metadata": {},
   "source": [
    "#### Ex 2.2\n",
    "\n",
    "Consider the bent coin model comparison example of Mackay section\n",
    "3.2-3 with $N=2$, where you take as model $H_0$ that the coin\n",
    "is fair with probability of 'head'\n",
    "$f=0.5$:\n",
    "\n",
    "  * Compute the posterior probability of the two models $H_0$ and $H_1$\n",
    "    for $N_H=0,1,2$.\n",
    "  * You will find that for $N_H=0,2$, model $H_1$ is more likely\n",
    "    and for $N_H=1$ model $H_0$ is more likely. Explain these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4563e",
   "metadata": {},
   "source": [
    "$$\\frac{p(H_1|D)}{p(H_0|D)}=2^N \\frac{N_H! (N-N_H)!}{(N+1)!}$$\n",
    "\n",
    "$p(H_0) = p(H_1) = \\frac{1}{2}$\n",
    "\n",
    "$p(D|H_0) = (\\frac{1}{2})^N$\n",
    "\n",
    "$p(D|H_1) = \\int_0^1 f^{N_H}(1-f)^{N_T}df = B(N_H+1, N_T+1)$\n",
    "\n",
    "$N=2$ \n",
    "\n",
    "i.e $N_H+N_T=2$\n",
    "\n",
    "$N_T=2-N_H$\n",
    "\n",
    "$p(D|H_0) = (\\frac{1}{2})^2$\n",
    "\n",
    "$p(D|H_0) = \\frac{1}{4}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d5317",
   "metadata": {},
   "source": [
    "$N_H=0$\n",
    "\n",
    "$p(D|H_1) = \\int_0^1 f^{N_H}(1-f)^{N_T}df = B(N_H+1, N_T+1)$\n",
    "\n",
    "$p(D|H_1) = B(1, 3) = \\frac{0!2!}{3!} = \\frac{2}{6} = \\frac{1}{3}$\n",
    "\n",
    "$p(H_1|D) = \\frac{p(D|H_1)}{p(D|H_1) + p(D|H_0)} = \\frac{\\frac{1}{3}}{ \\frac{1}{4} + \\frac{1}{3}}$\n",
    "\n",
    "$p(H_1|D) = \\frac{4}{7}$\n",
    "\n",
    "$p(H_0|D) = 1 - \\frac{4}{7} = \\frac{3}{7}$\n",
    "\n",
    "$H_1$ is more likely to occur when $N_H=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edb3dc",
   "metadata": {},
   "source": [
    "$N_H=1$\n",
    "\n",
    "$p(D|H_1) = B(N_H+1, N_T+1) = B(2, 2) = \\frac{1!1!}{3!} = \\frac{1}{6}$\n",
    "\n",
    "$p(H_1|D) = \\frac{p(D|H_1)}{p(D|H_1) + p(D|H_0)} = \\frac{\\frac{1}{6}}{ \\frac{1}{6} + \\frac{1}{4}} = \\frac{2}{5}$\n",
    "\n",
    "$p(H_0|D) = \\frac{3}{5}$\n",
    "\n",
    "$H_0$ is more likely to occur when $N_H=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d62867",
   "metadata": {},
   "source": [
    "$N_H=2$\n",
    "\n",
    "$p(D|H_1) = B(N_H+1, N_T+1) = B(3, 1) = \\frac{2!0!}{3!} = \\frac{2}{6} = \\frac{1}{3}$\n",
    "\n",
    "$p(H_1|D) = \\frac{p(D|H_1)}{p(D|H_1) + p(D|H_0)} = \\frac{\\frac{1}{3}}{ \\frac{1}{3} + \\frac{1}{4}} = \\frac{4}{7}$\n",
    "\n",
    "$p(H_0|D) = \\frac{3}{7}$\n",
    "\n",
    "$H_1$ is more likely to occur when $N_H=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624a472",
   "metadata": {},
   "source": [
    "$H_0$ is the fair model which assigns equal probabilities to all outcomes. \n",
    "\n",
    "$H_1$ is a flexible model which adapts the function to the distribution (uniform distribution here).\n",
    "\n",
    "$H_1$ starts with probabilites spread over the distribution (continuous) which can accomodate more values between [0,1]. Hence probabilities obtained are higher than what a fair model provides ($\\frac{1}{4}$ here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
